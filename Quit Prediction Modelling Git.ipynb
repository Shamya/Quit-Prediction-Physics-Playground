{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEVEL AGNOSTIC MODEL\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import average_precision_score, f1_score, roc_auc_score, precision_score\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "DO_STANDARDIZE = False\n",
    "DO_POLY = False\n",
    "DO_POLY_INTERACT = False\n",
    "DO_PCA = False\n",
    "DO_SELECT_FROM_MODEL = True\n",
    "DO_RFE = False\n",
    "\n",
    "NUM_FEAT = 40 #used only for PCA\n",
    "pca = PCA(n_components = NUM_FEAT)\n",
    "POLY_DEGREE = 2 #2nd degree polynomial features\n",
    "N_ESTIMATORS = 15 #number of trees\n",
    "DEPTH = 7 #depth of trees\n",
    "\n",
    "\n",
    "fname = \"ModelA_full_level_agnostic_test_new_all_extra_stud.csv\" ##CHANGE FILE NAME HERE\n",
    "df_ml = pd.read_csv(os.path.join(fname)\n",
    "\n",
    "Y = df_ml.loc[:, ['quit', 'fold']]\n",
    "X = df_ml.drop(['userId', 'total_records', 'quit', 'fold'], axis=1)\n",
    "\n",
    "#DATA PREPROCESSING - OUTER LOOP\n",
    "#standardize features\n",
    "if DO_STANDARDIZE is True:\n",
    "    X = (X - X.mean()) / X.std()#(X.max() - X.min())\n",
    "\n",
    "X['fold'] = Y['fold']\n",
    "\n",
    "N = X.shape[0] \n",
    "D = X.shape[1]-1 #extra fold column\n",
    "\n",
    "print \"N =\", N\n",
    "print \"D =\", D\n",
    "\n",
    "print \"Quit percent overall =\", float(sum(Y['quit']))/float(N)\n",
    "\n",
    "hyp_list = [a+1 for a in range(DEPTH)[::1]] #hyperparameter\n",
    "hyp_list2 = [a+1 for a in range(N_ESTIMATORS)[::3]]\n",
    "best_auc = -1\n",
    "best_f1 = -1\n",
    "best_hyp_auc = None\n",
    "best_hyp_f1 = None\n",
    "best_hyp_auc2 = None\n",
    "best_hyp_f12 = None\n",
    "\n",
    "#HYPERPARAMETER LOOP \n",
    "for hyp in hyp_list:\n",
    "    for hyp2 in hyp_list2:\n",
    "        auc = []\n",
    "        f1 = []\n",
    "        precision = []\n",
    "\n",
    "        #CROSS VALIDATION LOOP\n",
    "        for i in range(5):\n",
    "\n",
    "            #train-test split\n",
    "            st = set([1,2,3,4,5])\n",
    "            st.remove(i+1)\n",
    "\n",
    "            X_test = X[X['fold']==i+1]\n",
    "            X_test = X_test.drop(['fold'], axis=1).as_matrix()\n",
    "\n",
    "            X_train = X[X['fold'].isin(list(st))]\n",
    "            X_train = X_train.drop(['fold'], axis=1).as_matrix()\n",
    "\n",
    "            Y_test = Y[Y['fold']==i+1]\n",
    "            Y_test = Y_test.loc[:, 'quit'].as_matrix()\n",
    "\n",
    "            Y_train = Y[Y['fold'].isin(list(st))]\n",
    "            Y_train = Y_train.loc[:, 'quit'].as_matrix()\n",
    "\n",
    "            #DATA PREPROCESSING - INNER LOOP\n",
    "            #dimensionality reduction\n",
    "            if DO_PCA is True:\n",
    "                pca.fit(X_train) #NUM_FEAT specified earlier\n",
    "                X_train = pca.transform(X_train)\n",
    "                X_test = pca.transform(X_test) \n",
    "\n",
    "            #polynomial features \n",
    "            if DO_POLY is True:\n",
    "                poly = PolynomialFeatures(POLY_DEGREE) \n",
    "                poly.fit(X_train)\n",
    "                X_train = poly.transform(X_train)\n",
    "                X_test = poly.transform(X_test)\n",
    "\n",
    "            #polynomial features - interaction only\n",
    "            if DO_POLY_INTERACT is True:\n",
    "                poly = PolynomialFeatures(interaction_only=True)\n",
    "                poly.fit(X_train)\n",
    "                X_train = poly.transform(X_train)\n",
    "                X_test = poly.transform(X_test)\n",
    "\n",
    "            #clf = RandomForestClassifier(max_depth=hyp, n_estimators=N_ESTIMATORS, random_state=0)\n",
    "            clf = GradientBoostingClassifier(max_depth=hyp, n_estimators=hyp2, random_state=0)\n",
    "\n",
    "            #FEATURE SELECTION - Select from model\n",
    "            if DO_SELECT_FROM_MODEL is True:\n",
    "                try:\n",
    "                    clf.fit(X_train, Y_train)\n",
    "                except:\n",
    "                    skip_file.append(fname)\n",
    "                    continue \n",
    "                model = SelectFromModel(clf, prefit=True) #keep feature whose importance is greater than mean\n",
    "                X_train = model.transform(X_train)\n",
    "                X_test = model.transform(X_test)   \n",
    "\n",
    "            #FEATURE SELECTION LOOP \n",
    "            if DO_RFE is True:\n",
    "                rfe = RFE(clf, ) #half the features selected by default\n",
    "                rfe = rfe.fit(X_train, Y_train)\n",
    "                X_train = X_train[:,rfe.support_]\n",
    "                X_test = X_test[:,rfe.support_]\n",
    "\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "            Y_pred = clf.predict(X_test) #binary\n",
    "            Y_prob = clf.predict_proba(X_test) #probability\n",
    "\n",
    "            try:\n",
    "                auc.append(roc_auc_score(Y_test, Y_prob[:,1]))\n",
    "                f1.append(f1_score(Y_test, Y_pred))\n",
    "                precision.append(precision_score(Y_test, Y_pred))\n",
    "            except:\n",
    "                skip_file.append(fname)\n",
    "                continue #only happens for work it up - all quit in a fold\n",
    "\n",
    "        if np.mean(auc) > best_auc:\n",
    "            best_auc = np.mean(auc)\n",
    "            best_auc_f1 = np.mean(f1)\n",
    "            best_hyp_auc = hyp\n",
    "            best_hyp_auc2 = hyp2\n",
    "            print \"AUC - Hyp =\", best_hyp_auc, \"Hyp2 =\", best_hyp_auc2, \"F1 =\", best_auc_f1, \"CV auc =\", best_auc\n",
    "\n",
    "        if np.mean(f1) > best_f1:\n",
    "            best_f1 = np.mean(f1)\n",
    "            best_f1_auc = np.mean(auc)\n",
    "            best_hyp_f1 = hyp\n",
    "            best_hyp_f12 = hyp2\n",
    "            print \"F1 - Hyp =\", best_hyp_f1,\"Hyp2 =\", best_hyp_f12, \"CV f1 =\", best_f1, \"AUC =\", best_f1_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEVEL SPECIFIC MODELS \n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import average_precision_score, f1_score, roc_auc_score, precision_score\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, SelectFromModel\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "DO_SELECT_FROM_MODEL = True\n",
    "model_performance_dict = {}\n",
    "skip_file = []\n",
    "\n",
    "for fname in os.listdir(\"TestFullNewLevels\"):\n",
    "        \n",
    "    if fname.endswith(\".csv\") and not fname.startswith('.'):\n",
    "        print \"Processing\", fname\n",
    "        df_ml = pd.read_csv(os.path.join(\"TestFullNewLevels/\", fname))\n",
    "        num_users = len(df_ml['userId'].unique())\n",
    "\n",
    "        Y = df_ml.loc[:, ['quit', 'fold']]\n",
    "        X = df_ml.drop(['userId', 'total_records', 'quit'], axis=1)\n",
    "        X = df_ml.drop(['userId', 'total_records', 'quit', 'number_pauses_attempt','total_pause_duration_attempt', 'time_elapsed_last_pause', 'num_pauses', 'last_pause_duration'], axis=1)\n",
    "\n",
    "\n",
    "        N = X.shape[0] \n",
    "        D = X.shape[1]-1 #extra fold column\n",
    "\n",
    "        print \"N =\", N\n",
    "        print \"D =\", D\n",
    "\n",
    "        print \"Quit percent overall =\", float(sum(Y['quit']))/float(N)\n",
    "\n",
    "        auc = []\n",
    "        f1 = []\n",
    "        precision = []\n",
    "\n",
    "        #CROSS VALIDATION LOOP\n",
    "        for i in range(5):\n",
    "\n",
    "            #train-test split\n",
    "            st = set([1,2,3,4,5])\n",
    "            st.remove(i+1)\n",
    "\n",
    "            X_test = X[X['fold']==i+1]\n",
    "            X_test = X_test.drop(['fold'], axis=1).as_matrix()\n",
    "\n",
    "            X_train = X[X['fold'].isin(list(st))]\n",
    "            X_train = X_train.drop(['fold'], axis=1).as_matrix()\n",
    "\n",
    "            Y_test = Y[Y['fold']==i+1]\n",
    "            Y_test = Y_test.loc[:, 'quit'].as_matrix()\n",
    "\n",
    "            Y_train = Y[Y['fold'].isin(list(st))]\n",
    "            Y_train = Y_train.loc[:, 'quit'].as_matrix()\n",
    "\n",
    "            clf = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "            #FEATURE SELECTION - Select from model\n",
    "            if DO_SELECT_FROM_MODEL is True:\n",
    "                try:\n",
    "                    clf.fit(X_train, Y_train)\n",
    "                except:\n",
    "                    skip_file.append(fname)\n",
    "                    continue \n",
    "                model = SelectFromModel(clf, prefit=True) #keep feature whose importance is greater than mean\n",
    "                X_train = model.transform(X_train)\n",
    "                X_test = model.transform(X_test)   \n",
    "\n",
    "            clf.fit(X_train, Y_train)\n",
    "\n",
    "            Y_pred = clf.predict(X_test) #binary\n",
    "            Y_prob = clf.predict_proba(X_test) #probability\n",
    "\n",
    "            try:\n",
    "                auc.append(roc_auc_score(Y_test, Y_prob[:,1]))\n",
    "                f1.append(f1_score(Y_test, Y_pred))\n",
    "                precision.append(precision_score(Y_test, Y_pred))\n",
    "            except:\n",
    "                skip_file.append(fname)\n",
    "                continue #only happens for work it up - all quit in a fold\n",
    "        print \"---------------------------------------\"\n",
    "        print \"---------------------------------------\"\n",
    "\n",
    "        model_performance_dict[fname] = [np.mean(auc), np.mean(f1), float(sum(Y['quit']))/float(N), num_users]\n",
    "    \n",
    "print skip_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
